"use strict";(globalThis.webpackChunknautilus_trader=globalThis.webpackChunknautilus_trader||[]).push([[6520],{6803:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>h,frontMatter:()=>r,metadata:()=>a,toc:()=>o});const a=JSON.parse('{"id":"concepts/data","title":"Data","description":"NautilusTrader provides a set of built-in data types specifically designed to represent a trading domain.","source":"@site/docs/concepts/data.md","sourceDirName":"concepts","slug":"/concepts/data","permalink":"/concepts/data","draft":false,"unlisted":false,"editUrl":"https://github.com/Aloento/NautilusTraderDoc/tree/main/docs/concepts/data.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Cache","permalink":"/concepts/cache"},"next":{"title":"Execution","permalink":"/concepts/execution"}}');var s=t(7259),i=t(9087);const r={},l="Data",d={},o=[{value:"Order books",id:"order-books",level:2},{value:"Instruments",id:"instruments",level:2},{value:"Bars and aggregation",id:"bars-and-aggregation",level:2},{value:"Introduction to bars",id:"introduction-to-bars",level:3},{value:"Purpose of data aggregation",id:"purpose-of-data-aggregation",level:3},{value:"Aggregation methods",id:"aggregation-methods",level:3},{value:"Types of aggregation",id:"types-of-aggregation",level:3},{value:"Bar types",id:"bar-types",level:3},{value:"Aggregation sources",id:"aggregation-sources",level:3},{value:"Defining bar types with <em>string syntax</em>",id:"defining-bar-types-with-string-syntax",level:3},{value:"Standard bars",id:"standard-bars",level:4},{value:"Composite bars",id:"composite-bars",level:4},{value:"Aggregation syntax examples",id:"aggregation-syntax-examples",level:3},{value:"Trade-to-bar example",id:"trade-to-bar-example",level:4},{value:"Quote-to-bar example",id:"quote-to-bar-example",level:4},{value:"Bar-to-bar example",id:"bar-to-bar-example",level:4},{value:"Advanced bar-to-bar example",id:"advanced-bar-to-bar-example",level:4},{value:"Working with bars: request vs. subscribe",id:"working-with-bars-request-vs-subscribe",level:3},{value:"Historical data requests with aggregation",id:"historical-data-requests-with-aggregation",level:3},{value:"Common pitfalls",id:"common-pitfalls",level:3},{value:"Timestamps",id:"timestamps",level:2},{value:"Examples",id:"examples",level:3},{value:"Latency analysis",id:"latency-analysis",level:3},{value:"Environment-specific behavior",id:"environment-specific-behavior",level:3},{value:"Backtesting environment",id:"backtesting-environment",level:4},{value:"Live trading environment",id:"live-trading-environment",level:4},{value:"Other notes and considerations",id:"other-notes-and-considerations",level:3},{value:"Persisted data",id:"persisted-data",level:4},{value:"Data flow",id:"data-flow",level:2},{value:"Loading data",id:"loading-data",level:2},{value:"Data loaders",id:"data-loaders",level:3},{value:"Data wranglers",id:"data-wranglers",level:3},{value:"Transformation pipeline",id:"transformation-pipeline",level:3},{value:"Data catalog",id:"data-catalog",level:2},{value:"Overview and architecture",id:"overview-and-architecture",level:3},{value:"Initializing",id:"initializing",level:3},{value:"Filesystem protocols and storage options",id:"filesystem-protocols-and-storage-options",level:3},{value:"Supported filesystem protocols",id:"supported-filesystem-protocols",level:4},{value:"URI-based initialization",id:"uri-based-initialization",level:4},{value:"Writing data",id:"writing-data",level:3},{value:"File naming and data organization",id:"file-naming-and-data-organization",level:3},{value:"Reading data",id:"reading-data",level:3},{value:"<code>BacktestDataConfig</code> - data specification for backtests",id:"backtestdataconfig---data-specification-for-backtests",level:3},{value:"Core parameters",id:"core-parameters",level:4},{value:"Basic usage examples",id:"basic-usage-examples",level:4},{value:"Advanced configuration examples",id:"advanced-configuration-examples",level:4},{value:"Integration with BacktestRunConfig",id:"integration-with-backtestrunconfig",level:4},{value:"Data loading process",id:"data-loading-process",level:4},{value:"DataCatalogConfig - on-the-fly data loading",id:"datacatalogconfig---on-the-fly-data-loading",level:3},{value:"Core parameters",id:"core-parameters-1",level:4},{value:"Basic usage examples",id:"basic-usage-examples-1",level:4},{value:"Integration with live trading",id:"integration-with-live-trading",level:4},{value:"Streaming configuration",id:"streaming-configuration",level:4},{value:"Use cases",id:"use-cases",level:4},{value:"Query system and dual backend architecture",id:"query-system-and-dual-backend-architecture",level:3},{value:"Backend selection logic",id:"backend-selection-logic",level:4},{value:"Query methods and parameters",id:"query-methods-and-parameters",level:4},{value:"Catalog operations",id:"catalog-operations",level:3},{value:"Reset file names",id:"reset-file-names",level:4},{value:"Consolidate catalog",id:"consolidate-catalog",level:4},{value:"Consolidate catalog by period",id:"consolidate-catalog-by-period",level:4},{value:"Delete data range",id:"delete-data-range",level:4},{value:"Feather streaming and conversion",id:"feather-streaming-and-conversion",level:3},{value:"Catalog summary",id:"catalog-summary",level:3},{value:"Data migrations",id:"data-migrations",level:2},{value:"Migration tools",id:"migration-tools",level:3},{value:"<code>to_json</code>",id:"to_json",level:4},{value:"<code>to_parquet</code>",id:"to_parquet",level:4},{value:"Migration process",id:"migration-process",level:3},{value:"Migrating from standard-precision (64-bit) to high-precision (128-bit)",id:"migrating-from-standard-precision-64-bit-to-high-precision-128-bit",level:4},{value:"Migrating schema changes",id:"migrating-schema-changes",level:4},{value:"Best practices",id:"best-practices",level:3},{value:"Custom data",id:"custom-data",level:2},{value:"Publishing and receiving signal data",id:"publishing-and-receiving-signal-data",level:3},{value:"Option greeks example",id:"option-greeks-example",level:3},{value:"Publishing and receiving data",id:"publishing-and-receiving-data",level:4},{value:"Writing and reading data using the cache",id:"writing-and-reading-data-using-the-cache",level:4},{value:"Writing and reading data using a catalog",id:"writing-and-reading-data-using-a-catalog",level:4},{value:"Creating a custom data class automatically",id:"creating-a-custom-data-class-automatically",level:3},{value:"Custom data type stub",id:"custom-data-type-stub",level:4}];function c(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"data",children:"Data"})}),"\n",(0,s.jsx)(n.p,{children:"NautilusTrader provides a set of built-in data types specifically designed to represent a trading domain.\nThese data types include:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"OrderBookDelta"})," (L1/L2/L3): Represents the most granular order book updates."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"OrderBookDeltas"})," (L1/L2/L3): Batches multiple order book deltas for more efficient processing."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"OrderBookDepth10"}),": Aggregated order book snapshot (up to 10 levels per bid and ask side)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"QuoteTick"}),": Represents the best bid and ask prices along with their sizes at the top-of-book."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"TradeTick"}),": A single trade/match event between counterparties."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"Bar"}),": OHLCV (Open, High, Low, Close, Volume) bar/candle, aggregated using a specified ",(0,s.jsx)(n.em,{children:"aggregation method"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"MarkPriceUpdate"}),": The current mark price for an instrument (typically used in derivatives trading)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"IndexPriceUpdate"}),": The index price for an instrument (underlying price used for mark price calculations)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"FundingRateUpdate"}),": The funding rate for perpetual contracts (periodic payments between long and short positions)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"InstrumentStatus"}),": An instrument-level status event."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"InstrumentClose"}),": The closing price of an instrument."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"NautilusTrader is designed primarily to operate on granular order book data, providing the highest realism\nfor execution simulations in backtesting.\nHowever, backtests can also be conducted on any of the supported market data types, depending on the desired simulation fidelity."}),"\n",(0,s.jsx)(n.h2,{id:"order-books",children:"Order books"}),"\n",(0,s.jsx)(n.p,{children:"A high-performance order book implemented in Rust is available to maintain order book state based on provided data."}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"OrderBook"})," instances are maintained per instrument for both backtesting and live trading, with the following book types available:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"L3_MBO"}),": ",(0,s.jsx)(n.strong,{children:"Market by order (MBO)"})," or L3 data, uses every order book event at every price level, keyed by order ID."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"L2_MBP"}),": ",(0,s.jsx)(n.strong,{children:"Market by price (MBP)"})," or L2 data, aggregates order book events by price level."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"L1_MBP"}),": ",(0,s.jsx)(n.strong,{children:"Market by price (MBP)"})," or L1 data, also known as best bid and offer (BBO), captures only top-level updates."]}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsxs)(n.p,{children:["Top-of-book data, such as ",(0,s.jsx)(n.code,{children:"QuoteTick"}),", ",(0,s.jsx)(n.code,{children:"TradeTick"})," and ",(0,s.jsx)(n.code,{children:"Bar"}),", can also be used for backtesting, with markets operating on ",(0,s.jsx)(n.code,{children:"L1_MBP"})," book types."]})}),"\n",(0,s.jsx)(n.h2,{id:"instruments",children:"Instruments"}),"\n",(0,s.jsx)(n.p,{children:"The following instrument definitions are available:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"Betting"}),": Represents an instrument in a betting market."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"BinaryOption"}),": Represents a generic binary option instrument."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"Cfd"}),": Represents a Contract for Difference (CFD) instrument."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"Commodity"}),":  Represents a commodity instrument in a spot/cash market."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"CryptoFuture"}),": Represents a deliverable futures contract instrument, with crypto assets as underlying and for settlement."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"CryptoPerpetual"}),": Represents a crypto perpetual futures contract instrument (a.k.a. perpetual swap)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"CurrencyPair"}),": Represents a generic currency pair instrument in a spot/cash market."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"Equity"}),": Represents a generic equity instrument."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"FuturesContract"}),": Represents a generic deliverable futures contract instrument."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"FuturesSpread"}),": Represents a generic deliverable futures spread instrument."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"Index"}),": Represents a generic index instrument."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"OptionContract"}),": Represents a generic option contract instrument."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"OptionSpread"}),": Represents a generic option spread instrument."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"Synthetic"}),": Represents a synthetic instrument with prices derived from component instruments using a formula."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"bars-and-aggregation",children:"Bars and aggregation"}),"\n",(0,s.jsx)(n.h3,{id:"introduction-to-bars",children:"Introduction to bars"}),"\n",(0,s.jsxs)(n.p,{children:["A ",(0,s.jsx)(n.em,{children:"bar"})," (also known as a candle, candlestick or kline) is a data structure that represents\nprice and volume information over a specific period, including:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Opening price"}),"\n",(0,s.jsx)(n.li,{children:"Highest price"}),"\n",(0,s.jsx)(n.li,{children:"Lowest price"}),"\n",(0,s.jsx)(n.li,{children:"Closing price"}),"\n",(0,s.jsx)(n.li,{children:"Traded volume (or ticks as a volume proxy)"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["The system generates bars using an ",(0,s.jsx)(n.em,{children:"aggregation method"})," that groups data by specific criteria."]}),"\n",(0,s.jsx)(n.h3,{id:"purpose-of-data-aggregation",children:"Purpose of data aggregation"}),"\n",(0,s.jsx)(n.p,{children:"Data aggregation in NautilusTrader transforms granular market data into structured bars or candles for several reasons:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"To provide data for technical indicators and strategy development."}),"\n",(0,s.jsx)(n.li,{children:"Because time-aggregated data (like minute bars) are often sufficient for many strategies."}),"\n",(0,s.jsx)(n.li,{children:"To reduce costs compared to high-frequency L1/L2/L3 market data."}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"aggregation-methods",children:"Aggregation methods"}),"\n",(0,s.jsx)(n.p,{children:"The platform implements various aggregation methods:"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{style:{textAlign:"left"},children:"Name"}),(0,s.jsx)(n.th,{style:{textAlign:"left"},children:"Description"}),(0,s.jsx)(n.th,{style:{textAlign:"left"},children:"Category"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"TICK"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Aggregation of a number of ticks."}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Threshold"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"TICK_IMBALANCE"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Aggregation of the buy/sell imbalance of ticks."}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Threshold"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"TICK_RUNS"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Aggregation of sequential buy/sell runs of ticks."}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Information"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"VOLUME"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Aggregation of traded volume."}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Threshold"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"VOLUME_IMBALANCE"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Aggregation of the buy/sell imbalance of traded volume."}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Threshold"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"VOLUME_RUNS"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Aggregation of sequential runs of buy/sell traded volume."}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Information"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"VALUE"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:'Aggregation of the notional value of trades (also known as "Dollar bars").'}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Threshold"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"VALUE_IMBALANCE"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Aggregation of the buy/sell imbalance of trading by notional value."}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Information"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"VALUE_RUNS"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Aggregation of sequential buy/sell runs of trading by notional value."}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Threshold"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"RENKO"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Aggregation based on fixed price movements (brick size in ticks)."}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Threshold"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"MILLISECOND"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Aggregation of time intervals with millisecond granularity."}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Time"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"SECOND"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Aggregation of time intervals with second granularity."}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Time"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"MINUTE"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Aggregation of time intervals with minute granularity."}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Time"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"HOUR"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Aggregation of time intervals with hour granularity."}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Time"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"DAY"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Aggregation of time intervals with day granularity."}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Time"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"WEEK"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Aggregation of time intervals with week granularity."}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Time"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"MONTH"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Aggregation of time intervals with month granularity."}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Time"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:(0,s.jsx)(n.code,{children:"YEAR"})}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Aggregation of time intervals with year granularity."}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Time"})]})]})]}),"\n",(0,s.jsxs)(n.admonition,{type:"note",children:[(0,s.jsx)(n.p,{children:"The following bar aggregations are not currently implemented:"}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"VOLUME_IMBALANCE"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"VOLUME_RUNS"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"VALUE_IMBALANCE"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"VALUE_RUNS"})}),"\n"]})]}),"\n",(0,s.jsx)(n.h3,{id:"types-of-aggregation",children:"Types of aggregation"}),"\n",(0,s.jsx)(n.p,{children:"NautilusTrader implements three distinct data aggregation methods:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Trade-to-bar aggregation"}),": Creates bars from ",(0,s.jsx)(n.code,{children:"TradeTick"})," objects (executed trades)"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Use case: For strategies analyzing execution prices or when working directly with trade data."}),"\n",(0,s.jsxs)(n.li,{children:["Always uses the ",(0,s.jsx)(n.code,{children:"LAST"})," price type in the bar specification."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Quote-to-bar aggregation"}),": Creates bars from ",(0,s.jsx)(n.code,{children:"QuoteTick"})," objects (bid/ask prices)"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Use case: For strategies focusing on bid/ask spreads or market depth analysis."}),"\n",(0,s.jsxs)(n.li,{children:["Uses ",(0,s.jsx)(n.code,{children:"BID"}),", ",(0,s.jsx)(n.code,{children:"ASK"}),", or ",(0,s.jsx)(n.code,{children:"MID"})," price types in the bar specification."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Bar-to-bar aggregation"}),": Creates larger-timeframe ",(0,s.jsx)(n.code,{children:"Bar"})," objects from smaller-timeframe ",(0,s.jsx)(n.code,{children:"Bar"})," objects"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Use case: For resampling existing smaller timeframe bars (1-minute) into larger timeframes (5-minute, hourly)."}),"\n",(0,s.jsxs)(n.li,{children:["Always requires the ",(0,s.jsx)(n.code,{children:"@"})," symbol in the specification."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"bar-types",children:"Bar types"}),"\n",(0,s.jsxs)(n.p,{children:["NautilusTrader defines a unique ",(0,s.jsx)(n.em,{children:"bar type"})," (",(0,s.jsx)(n.code,{children:"BarType"})," class) based on the following components:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Instrument ID"})," (",(0,s.jsx)(n.code,{children:"InstrumentId"}),"): Specifies the particular instrument for the bar."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Bar Specification"})," (",(0,s.jsx)(n.code,{children:"BarSpecification"}),"):","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"step"}),": Defines the interval or frequency of each bar."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"aggregation"}),": Specifies the method used for data aggregation (see the above table)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"price_type"}),": Indicates the price basis of the bar (e.g., bid, ask, mid, last)."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Aggregation Source"})," (",(0,s.jsx)(n.code,{children:"AggregationSource"}),"): Indicates whether the bar was aggregated internally (within Nautilus)."]}),"\n",(0,s.jsx)(n.li,{children:"or externally (by a trading venue or data provider)."}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Bar types can also be classified as either ",(0,s.jsx)(n.em,{children:"standard"})," or ",(0,s.jsx)(n.em,{children:"composite"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Standard"}),": Generated from granular market data, such as quote-ticks or trade-ticks."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Composite"}),": Derived from a higher-granularity bar type through subsampling (like 5-MINUTE bars aggregate from 1-MINUTE bars)."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"aggregation-sources",children:"Aggregation sources"}),"\n",(0,s.jsxs)(n.p,{children:["Bar data aggregation can be either ",(0,s.jsx)(n.em,{children:"internal"})," or ",(0,s.jsx)(n.em,{children:"external"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"INTERNAL"}),": The bar is aggregated inside the local Nautilus system boundary."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"EXTERNAL"}),": The bar is aggregated outside the local Nautilus system boundary (typically by a trading venue or data provider)."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["For bar-to-bar aggregation, the target bar type is always ",(0,s.jsx)(n.code,{children:"INTERNAL"})," (since you're doing the aggregation within NautilusTrader),\nbut the source bars can be either ",(0,s.jsx)(n.code,{children:"INTERNAL"})," or ",(0,s.jsx)(n.code,{children:"EXTERNAL"}),", i.e., you can aggregate externally provided bars or already\naggregated internal bars."]}),"\n",(0,s.jsxs)(n.h3,{id:"defining-bar-types-with-string-syntax",children:["Defining bar types with ",(0,s.jsx)(n.em,{children:"string syntax"})]}),"\n",(0,s.jsx)(n.h4,{id:"standard-bars",children:"Standard bars"}),"\n",(0,s.jsx)(n.p,{children:"You can define standard bar types from strings using the following convention:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.code,{children:"{instrument_id}-{step}-{aggregation}-{price_type}-{INTERNAL | EXTERNAL}"})}),"\n",(0,s.jsxs)(n.p,{children:["For example, to define a ",(0,s.jsx)(n.code,{children:"BarType"})," for AAPL trades (last price) on Nasdaq (XNAS) using a 5-minute interval\naggregated from trades locally by Nautilus:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'bar_type = BarType.from_str("AAPL.XNAS-5-MINUTE-LAST-INTERNAL")\n'})}),"\n",(0,s.jsx)(n.h4,{id:"composite-bars",children:"Composite bars"}),"\n",(0,s.jsx)(n.p,{children:"Composite bars are derived by aggregating higher-granularity bars into the desired bar type. To define a composite bar,\nuse this convention:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.code,{children:"{instrument_id}-{step}-{aggregation}-{price_type}-INTERNAL@{step}-{aggregation}-{INTERNAL | EXTERNAL}"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Notes"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["The derived bar type must use an ",(0,s.jsx)(n.code,{children:"INTERNAL"})," aggregation source (since this is how the bar is aggregated)."]}),"\n",(0,s.jsx)(n.li,{children:"The sampled bar type must have a higher granularity than the derived bar type."}),"\n",(0,s.jsx)(n.li,{children:"The sampled instrument ID is inferred to match that of the derived bar type."}),"\n",(0,s.jsxs)(n.li,{children:["Composite bars can be aggregated ",(0,s.jsx)(n.em,{children:"from"})," ",(0,s.jsx)(n.code,{children:"INTERNAL"})," or ",(0,s.jsx)(n.code,{children:"EXTERNAL"})," aggregation sources."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["For example, to define a ",(0,s.jsx)(n.code,{children:"BarType"})," for AAPL trades (last price) on Nasdaq (XNAS) using a 5-minute interval\naggregated locally by Nautilus, from 1-minute interval bars aggregated externally:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'bar_type = BarType.from_str("AAPL.XNAS-5-MINUTE-LAST-INTERNAL@1-MINUTE-EXTERNAL")\n'})}),"\n",(0,s.jsx)(n.h3,{id:"aggregation-syntax-examples",children:"Aggregation syntax examples"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"BarType"})," string format encodes both the target bar type and, optionally, the source data type:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"{instrument_id}-{step}-{aggregation}-{price_type}-{source}@{step}-{aggregation}-{source}\n"})}),"\n",(0,s.jsxs)(n.p,{children:["The part after the ",(0,s.jsx)(n.code,{children:"@"})," symbol is optional and only used for bar-to-bar aggregation:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:["Without ",(0,s.jsx)(n.code,{children:"@"})]}),": Aggregates from ",(0,s.jsx)(n.code,{children:"TradeTick"})," objects (when price_type is ",(0,s.jsx)(n.code,{children:"LAST"}),") or ",(0,s.jsx)(n.code,{children:"QuoteTick"})," objects (when price_type is ",(0,s.jsx)(n.code,{children:"BID"}),", ",(0,s.jsx)(n.code,{children:"ASK"}),", or ",(0,s.jsx)(n.code,{children:"MID"}),")."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:["With ",(0,s.jsx)(n.code,{children:"@"})]}),": Aggregates from existing ",(0,s.jsx)(n.code,{children:"Bar"})," objects (specifying the source bar type)."]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"trade-to-bar-example",children:"Trade-to-bar example"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def on_start(self) -> None:\n    # Define a bar type for aggregating from TradeTick objects\n    # Uses price_type=LAST which indicates TradeTick data as source\n    bar_type = BarType.from_str("6EH4.XCME-50-VOLUME-LAST-INTERNAL")\n\n    # Request historical data (will receive bars in on_historical_data handler)\n    self.request_bars(bar_type)\n\n    # Subscribe to live data (will receive bars in on_bar handler)\n    self.subscribe_bars(bar_type)\n'})}),"\n",(0,s.jsx)(n.h4,{id:"quote-to-bar-example",children:"Quote-to-bar example"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def on_start(self) -> None:\n    # Create 1-minute bars from ASK prices (in QuoteTick objects)\n    bar_type_ask = BarType.from_str("6EH4.XCME-1-MINUTE-ASK-INTERNAL")\n\n    # Create 1-minute bars from BID prices (in QuoteTick objects)\n    bar_type_bid = BarType.from_str("6EH4.XCME-1-MINUTE-BID-INTERNAL")\n\n    # Create 1-minute bars from MID prices (middle between ASK and BID prices in QuoteTick objects)\n    bar_type_mid = BarType.from_str("6EH4.XCME-1-MINUTE-MID-INTERNAL")\n\n    # Request historical data and subscribe to live data\n    self.request_bars(bar_type_ask)    # Historical bars processed in on_historical_data\n    self.subscribe_bars(bar_type_ask)  # Live bars processed in on_bar\n'})}),"\n",(0,s.jsx)(n.h4,{id:"bar-to-bar-example",children:"Bar-to-bar example"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def on_start(self) -> None:\n    # Create 5-minute bars from 1-minute bars (Bar objects)\n    # Format: target_bar_type@source_bar_type\n    # Note: price type (LAST) is only needed on the left target side, not on the source side\n    bar_type = BarType.from_str("6EH4.XCME-5-MINUTE-LAST-INTERNAL@1-MINUTE-EXTERNAL")\n\n    # Request historical data (processed in on_historical_data(...) handler)\n    self.request_bars(bar_type)\n\n    # Subscribe to live updates (processed in on_bar(...) handler)\n    self.subscribe_bars(bar_type)\n'})}),"\n",(0,s.jsx)(n.h4,{id:"advanced-bar-to-bar-example",children:"Advanced bar-to-bar example"}),"\n",(0,s.jsx)(n.p,{children:"You can create complex aggregation chains where you aggregate from already aggregated bars:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# First create 1-minute bars from TradeTick objects (LAST indicates TradeTick source)\nprimary_bar_type = BarType.from_str("6EH4.XCME-1-MINUTE-LAST-INTERNAL")\n\n# Then create 5-minute bars from 1-minute bars\n# Note the @1-MINUTE-INTERNAL part identifying the source bars\nintermediate_bar_type = BarType.from_str("6EH4.XCME-5-MINUTE-LAST-INTERNAL@1-MINUTE-INTERNAL")\n\n# Then create hourly bars from 5-minute bars\n# Note the @5-MINUTE-INTERNAL part identifying the source bars\nhourly_bar_type = BarType.from_str("6EH4.XCME-1-HOUR-LAST-INTERNAL@5-MINUTE-INTERNAL")\n'})}),"\n",(0,s.jsx)(n.h3,{id:"working-with-bars-request-vs-subscribe",children:"Working with bars: request vs. subscribe"}),"\n",(0,s.jsx)(n.p,{children:"NautilusTrader provides two distinct operations for working with bars:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"request_bars()"})}),": Fetches historical data processed by the ",(0,s.jsx)(n.code,{children:"on_historical_data()"})," handler."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"subscribe_bars()"})}),": Establishes a real-time data feed processed by the ",(0,s.jsx)(n.code,{children:"on_bar()"})," handler."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"These methods work together in a typical workflow:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["First, ",(0,s.jsx)(n.code,{children:"request_bars()"})," loads historical data to initialize indicators or state of strategy with past market behavior."]}),"\n",(0,s.jsxs)(n.li,{children:["Then, ",(0,s.jsx)(n.code,{children:"subscribe_bars()"})," ensures the strategy continues receiving new bars as they form in real-time."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Example usage in ",(0,s.jsx)(n.code,{children:"on_start()"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def on_start(self) -> None:\n    # Define bar type\n    bar_type = BarType.from_str("6EH4.XCME-5-MINUTE-LAST-INTERNAL")\n\n    # Request historical data to initialize indicators\n    # These bars will be delivered to the on_historical_data(...) handler in strategy\n    self.request_bars(bar_type)\n\n    # Subscribe to real-time updates\n    # New bars will be delivered to the on_bar(...) handler in strategy\n    self.subscribe_bars(bar_type)\n\n    # Register indicators to receive bar updates (they will be automatically updated)\n    self.register_indicator_for_bars(bar_type, self.my_indicator)\n'})}),"\n",(0,s.jsx)(n.p,{children:"Required handlers in your strategy to receive the data:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def on_historical_data(self, data):\n    # Processes batches of historical bars from request_bars()\n    # Note: indicators registered with register_indicator_for_bars\n    # are updated automatically with historical data\n    pass\n\ndef on_bar(self, bar):\n    # Processes individual bars in real-time from subscribe_bars()\n    # Indicators registered with this bar type will update automatically and they will be updated before this handler is called\n    pass\n"})}),"\n",(0,s.jsx)(n.h3,{id:"historical-data-requests-with-aggregation",children:"Historical data requests with aggregation"}),"\n",(0,s.jsxs)(n.p,{children:["When requesting historical bars for backtesting or initializing indicators, you can use the ",(0,s.jsx)(n.code,{children:"request_bars()"})," method, which supports both direct requests and aggregation:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Request raw 1-minute bars (aggregated from TradeTick objects as indicated by LAST price type)\nself.request_bars(BarType.from_str("6EH4.XCME-1-MINUTE-LAST-EXTERNAL"))\n\n# Request 5-minute bars aggregated from 1-minute bars\nself.request_bars(BarType.from_str("6EH4.XCME-5-MINUTE-LAST-INTERNAL@1-MINUTE-EXTERNAL"))\n'})}),"\n",(0,s.jsxs)(n.p,{children:["If historical aggregated bars are needed, you can use specialized request ",(0,s.jsx)(n.code,{children:"request_aggregated_bars()"})," method:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Request bars that are aggregated from historical trade ticks\nself.request_aggregated_bars([BarType.from_str("6EH4.XCME-100-VOLUME-LAST-INTERNAL")])\n\n# Request bars that are aggregated from other bars\nself.request_aggregated_bars([BarType.from_str("6EH4.XCME-5-MINUTE-LAST-INTERNAL@1-MINUTE-EXTERNAL")])\n'})}),"\n",(0,s.jsx)(n.h3,{id:"common-pitfalls",children:"Common pitfalls"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Register indicators before requesting data"}),": Ensure indicators are registered before requesting historical data so they get updated properly."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Correct order\nself.register_indicator_for_bars(bar_type, self.ema)\nself.request_bars(bar_type)\n\n# Incorrect order\nself.request_bars(bar_type)  # Indicator won't receive historical data\nself.register_indicator_for_bars(bar_type, self.ema)\n"})}),"\n",(0,s.jsx)(n.h2,{id:"timestamps",children:"Timestamps"}),"\n",(0,s.jsx)(n.p,{children:"The platform uses two fundamental timestamp fields that appear across many objects, including market data, orders, and events.\nThese timestamps serve distinct purposes and help maintain precise timing information throughout the system:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"ts_event"}),": UNIX timestamp (nanoseconds) representing when an event actually occurred."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"ts_init"}),": UNIX timestamp (nanoseconds) representing when Nautilus created the internal object representing that event."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"examples",children:"Examples"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:(0,s.jsx)(n.strong,{children:"Event Type"})}),(0,s.jsx)(n.th,{children:(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"ts_event"})})}),(0,s.jsx)(n.th,{children:(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"ts_init"})})})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"TradeTick"})}),(0,s.jsx)(n.td,{children:"Time when trade occurred at the exchange."}),(0,s.jsx)(n.td,{children:"Time when Nautilus received the trade data."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"QuoteTick"})}),(0,s.jsx)(n.td,{children:"Time when quote occurred at the exchange."}),(0,s.jsx)(n.td,{children:"Time when Nautilus received the quote data."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"OrderBookDelta"})}),(0,s.jsx)(n.td,{children:"Time when order book update occurred at the exchange."}),(0,s.jsx)(n.td,{children:"Time when Nautilus received the order book update."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"Bar"})}),(0,s.jsx)(n.td,{children:"Time of the bar's closing (exact minute/hour)."}),(0,s.jsx)(n.td,{children:"Time when Nautilus generated (for internal bars) or received the bar data (for external bars)."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"OrderFilled"})}),(0,s.jsx)(n.td,{children:"Time when order was filled at the exchange."}),(0,s.jsx)(n.td,{children:"Time when Nautilus received and processed the fill confirmation."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"OrderCanceled"})}),(0,s.jsx)(n.td,{children:"Time when cancellation was processed at the exchange."}),(0,s.jsx)(n.td,{children:"Time when Nautilus received and processed the cancellation confirmation."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"NewsEvent"})}),(0,s.jsx)(n.td,{children:"Time when the news was published."}),(0,s.jsx)(n.td,{children:"Time when the event object was created (if internal event) or received (if external event) in Nautilus."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Custom event"}),(0,s.jsx)(n.td,{children:"Time when event conditions actually occurred."}),(0,s.jsx)(n.td,{children:"Time when the event object was created (if internal event) or received (if external event) in Nautilus."})]})]})]}),"\n",(0,s.jsxs)(n.admonition,{type:"note",children:[(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"ts_init"}),' field represents a more general concept than just the "time of reception" for events.\nIt denotes the timestamp when an object, such as a data point or command, was initialized within Nautilus.\nThis distinction is important because ',(0,s.jsx)(n.code,{children:"ts_init"}),' is not exclusive to "received events" \u2014 it applies to any internal\ninitialization process.']}),(0,s.jsxs)(n.p,{children:["For example, the ",(0,s.jsx)(n.code,{children:"ts_init"})," field is also used for commands, where the concept of reception does not apply.\nThis broader definition ensures consistent handling of initialization timestamps across various object types in the system."]})]}),"\n",(0,s.jsx)(n.h3,{id:"latency-analysis",children:"Latency analysis"}),"\n",(0,s.jsx)(n.p,{children:"The dual timestamp system enables latency analysis within the platform:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Latency can be calculated as ",(0,s.jsx)(n.code,{children:"ts_init - ts_event"}),"."]}),"\n",(0,s.jsx)(n.li,{children:"This difference represents total system latency, including network transmission time, processing overhead, and any queueing delays."}),"\n",(0,s.jsx)(n.li,{children:"It's important to remember that the clocks producing these timestamps are likely not synchronized."}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"environment-specific-behavior",children:"Environment-specific behavior"}),"\n",(0,s.jsx)(n.h4,{id:"backtesting-environment",children:"Backtesting environment"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Data is ordered by ",(0,s.jsx)(n.code,{children:"ts_init"})," using a stable sort."]}),"\n",(0,s.jsx)(n.li,{children:"This behavior ensures deterministic processing order and simulates realistic system behavior, including latencies."}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"live-trading-environment",children:"Live trading environment"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["The system processes data as it arrives to minimize latency and enable real-time decisions.","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"ts_init"})," field records the exact moment when data is received by Nautilus in real-time."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"ts_event"})," reflects the time the event occurred externally, enabling accurate comparisons between external event timing and system reception."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["We can use the difference between ",(0,s.jsx)(n.code,{children:"ts_init"})," and ",(0,s.jsx)(n.code,{children:"ts_event"})," to detect network or processing delays."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"other-notes-and-considerations",children:"Other notes and considerations"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["For data from external sources, ",(0,s.jsx)(n.code,{children:"ts_init"})," is always the same as or later than ",(0,s.jsx)(n.code,{children:"ts_event"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["For data created within Nautilus, ",(0,s.jsx)(n.code,{children:"ts_init"})," and ",(0,s.jsx)(n.code,{children:"ts_event"})," can be the same because the object is initialized at the same time the event happens."]}),"\n",(0,s.jsxs)(n.li,{children:["Not every type with a ",(0,s.jsx)(n.code,{children:"ts_init"})," field necessarily has a ",(0,s.jsx)(n.code,{children:"ts_event"})," field. This reflects cases where:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"The initialization of an object happens at the same time as the event itself."}),"\n",(0,s.jsx)(n.li,{children:"The concept of an external event time does not apply."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"persisted-data",children:"Persisted data"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"ts_init"})," field indicates when the message was originally received."]}),"\n",(0,s.jsx)(n.h2,{id:"data-flow",children:"Data flow"}),"\n",(0,s.jsxs)(n.p,{children:["The platform ensures consistency by flowing data through the same pathways across all system ",(0,s.jsx)(n.a,{href:"/concepts/architecture#environment-contexts",children:"environment contexts"}),"\n(e.g., ",(0,s.jsx)(n.code,{children:"backtest"}),", ",(0,s.jsx)(n.code,{children:"sandbox"}),", ",(0,s.jsx)(n.code,{children:"live"}),"). Data is primarily transported via the ",(0,s.jsx)(n.code,{children:"MessageBus"})," to the ",(0,s.jsx)(n.code,{children:"DataEngine"}),"\nand then distributed to subscribed or registered handlers."]}),"\n",(0,s.jsxs)(n.p,{children:["For users who need more flexibility, the platform also supports the creation of custom data types.\nFor details on how to implement user-defined data types, see the ",(0,s.jsx)(n.a,{href:"#custom-data",children:"Custom Data"})," section below."]}),"\n",(0,s.jsx)(n.h2,{id:"loading-data",children:"Loading data"}),"\n",(0,s.jsx)(n.p,{children:"NautilusTrader facilitates data loading and conversion for three main use cases:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Providing data for a ",(0,s.jsx)(n.code,{children:"BacktestEngine"})," to run backtests."]}),"\n",(0,s.jsxs)(n.li,{children:["Persisting the Nautilus-specific Parquet format for the data catalog via ",(0,s.jsx)(n.code,{children:"ParquetDataCatalog.write_data(...)"})," to be later used with a ",(0,s.jsx)(n.code,{children:"BacktestNode"}),"."]}),"\n",(0,s.jsx)(n.li,{children:"For research purposes (to ensure data is consistent between research and backtesting)."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Regardless of the destination, the process remains the same: converting diverse external data formats into Nautilus data structures."}),"\n",(0,s.jsx)(n.p,{children:"To achieve this, two main components are necessary:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["A type of DataLoader (normally specific per raw source/format) which can read the data and return a ",(0,s.jsx)(n.code,{children:"pd.DataFrame"})," with the correct schema for the desired Nautilus object."]}),"\n",(0,s.jsxs)(n.li,{children:["A type of DataWrangler (specific per data type) which takes this ",(0,s.jsx)(n.code,{children:"pd.DataFrame"})," and returns a ",(0,s.jsx)(n.code,{children:"list[Data]"})," of Nautilus objects."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"data-loaders",children:"Data loaders"}),"\n",(0,s.jsxs)(n.p,{children:["Data loader components are typically specific for the raw source/format and per integration. For instance, Binance order book data is stored in its raw CSV file form with\nan entirely different format to ",(0,s.jsx)(n.a,{href:"https://databento.com/docs/knowledge-base/new-users/dbn-encoding/getting-started-with-dbn",children:"Databento Binary Encoding (DBN)"})," files."]}),"\n",(0,s.jsx)(n.h3,{id:"data-wranglers",children:"Data wranglers"}),"\n",(0,s.jsxs)(n.p,{children:["Data wranglers are implemented per specific Nautilus data type, and can be found in the ",(0,s.jsx)(n.code,{children:"nautilus_trader.persistence.wranglers"})," module.\nCurrently there exists:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"OrderBookDeltaDataWrangler"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"OrderBookDepth10DataWrangler"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"QuoteTickDataWrangler"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"TradeTickDataWrangler"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"BarDataWrangler"})}),"\n"]}),"\n",(0,s.jsxs)(n.admonition,{type:"warning",children:[(0,s.jsxs)(n.p,{children:["There are a number of ",(0,s.jsx)(n.strong,{children:"DataWrangler v2"})," components, which will take a ",(0,s.jsx)(n.code,{children:"pd.DataFrame"})," typically\nwith a different fixed width Nautilus Arrow v2 schema, and output PyO3 Nautilus objects which are only compatible with the new version\nof the Nautilus core, currently in development."]}),(0,s.jsx)(n.p,{children:(0,s.jsxs)(n.strong,{children:["These PyO3 provided data objects are not compatible where the legacy Cython objects are currently used (e.g., adding directly to a ",(0,s.jsx)(n.code,{children:"BacktestEngine"}),")."]})})]}),"\n",(0,s.jsx)(n.h3,{id:"transformation-pipeline",children:"Transformation pipeline"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Process flow"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Raw data (e.g., CSV) is input into the pipeline."}),"\n",(0,s.jsxs)(n.li,{children:["DataLoader processes the raw data and converts it into a ",(0,s.jsx)(n.code,{children:"pd.DataFrame"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["DataWrangler further processes the ",(0,s.jsx)(n.code,{children:"pd.DataFrame"})," to generate a list of Nautilus objects."]}),"\n",(0,s.jsxs)(n.li,{children:["The Nautilus ",(0,s.jsx)(n.code,{children:"list[Data]"})," is the output of the data loading process."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"The following diagram illustrates how raw data is transformed into Nautilus data structures:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502          \u2502    \u2502                      \u2502                  \u2502                      \u2502\n  \u2502          \u2502    \u2502                      \u2502                  \u2502                      \u2502\n  \u2502 Raw data \u2502    \u2502                      \u2502  `pd.DataFrame`  \u2502                      \u2502\n  \u2502 (CSV)    \u251c\u2500\u2500\u2500\u25ba\u2502      DataLoader      \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502     DataWrangler     \u251c\u2500\u2500\u2500\u25ba Nautilus `list[Data]`\n  \u2502          \u2502    \u2502                      \u2502                  \u2502                      \u2502\n  \u2502          \u2502    \u2502                      \u2502                  \u2502                      \u2502\n  \u2502          \u2502    \u2502                      \u2502                  \u2502                      \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n"})}),"\n",(0,s.jsx)(n.p,{children:"Concretely, this would involve:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"BinanceOrderBookDeltaDataLoader.load(...)"})," which reads CSV files provided by Binance from disk, and returns a ",(0,s.jsx)(n.code,{children:"pd.DataFrame"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"OrderBookDeltaDataWrangler.process(...)"})," which takes the ",(0,s.jsx)(n.code,{children:"pd.DataFrame"})," and returns ",(0,s.jsx)(n.code,{children:"list[OrderBookDelta]"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"The following example shows how to accomplish the above in Python:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from nautilus_trader import TEST_DATA_DIR\nfrom nautilus_trader.adapters.binance.loaders import BinanceOrderBookDeltaDataLoader\nfrom nautilus_trader.persistence.wranglers import OrderBookDeltaDataWrangler\nfrom nautilus_trader.test_kit.providers import TestInstrumentProvider\n\n\n# Load raw data\ndata_path = TEST_DATA_DIR / "binance" / "btcusdt-depth-snap.csv"\ndf = BinanceOrderBookDeltaDataLoader.load(data_path)\n\n# Set up a wrangler\ninstrument = TestInstrumentProvider.btcusdt_binance()\nwrangler = OrderBookDeltaDataWrangler(instrument)\n\n# Process to a list `OrderBookDelta` Nautilus objects\ndeltas = wrangler.process(df)\n'})}),"\n",(0,s.jsx)(n.h2,{id:"data-catalog",children:"Data catalog"}),"\n",(0,s.jsxs)(n.p,{children:["The data catalog is a central store for Nautilus data, persisted in the ",(0,s.jsx)(n.a,{href:"https://parquet.apache.org",children:"Parquet"})," file format. It serves as the primary data management system for both backtesting and live trading scenarios, providing efficient storage, retrieval, and streaming capabilities for market data."]}),"\n",(0,s.jsx)(n.h3,{id:"overview-and-architecture",children:"Overview and architecture"}),"\n",(0,s.jsx)(n.p,{children:"The NautilusTrader data catalog is built on a dual-backend architecture that combines the performance of Rust with the flexibility of Python:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Core components:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"ParquetDataCatalog"}),": The main Python interface for data operations."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Rust backend"}),": High-performance query engine for core data types (OrderBookDelta, QuoteTick, TradeTick, Bar, MarkPriceUpdate)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"PyArrow backend"}),": Flexible fallback for custom data types and advanced filtering."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"fsspec integration"}),": Support for local and cloud storage (S3, GCS, Azure, etc.)."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Key benefits"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Performance"}),": Rust backend provides optimized query performance for core market data types."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Flexibility"}),": PyArrow backend handles custom data types and complex filtering scenarios."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Scalability"}),": Efficient compression and columnar storage reduce storage costs and improve I/O performance."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Cloud native"}),": Built-in support for cloud storage providers through fsspec."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"No dependencies"}),": Self-contained solution requiring no external databases or services."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Storage format advantages:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Superior compression ratio and read performance compared to CSV/JSON/HDF5."}),"\n",(0,s.jsx)(n.li,{children:"Columnar storage enables efficient filtering and aggregation."}),"\n",(0,s.jsx)(n.li,{children:"Schema evolution support for data model changes."}),"\n",(0,s.jsx)(n.li,{children:"Cross-language compatibility (Python, Rust, Java, C++, etc.)."}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["The Arrow schemas used for the Parquet format are primarily single-sourced in the core ",(0,s.jsx)(n.code,{children:"persistence"})," Rust crate, with some legacy schemas available from the ",(0,s.jsx)(n.code,{children:"/serialization/arrow/schema.py"})," module."]}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsx)(n.p,{children:"The current plan is to eventually phase out the Python schemas module, so that all schemas are single sourced in the Rust core for consistency and performance."})}),"\n",(0,s.jsx)(n.h3,{id:"initializing",children:"Initializing"}),"\n",(0,s.jsxs)(n.p,{children:["The data catalog can be initialized from a ",(0,s.jsx)(n.code,{children:"NAUTILUS_PATH"})," environment variable, or by explicitly passing in a path like object."]}),"\n",(0,s.jsxs)(n.admonition,{title:"NAUTILUS_PATH environment variable",type:"note",children:[(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"NAUTILUS_PATH"})," environment variable should point to the ",(0,s.jsx)(n.strong,{children:"root"})," directory containing your Nautilus data. The catalog will automatically append ",(0,s.jsx)(n.code,{children:"/catalog"})," to this path."]}),(0,s.jsx)(n.p,{children:"For example:"}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["If ",(0,s.jsx)(n.code,{children:"NAUTILUS_PATH=/home/user/trading_data"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["Then the catalog will be located at ",(0,s.jsx)(n.code,{children:"/home/user/trading_data/catalog"}),"."]}),"\n"]}),(0,s.jsxs)(n.p,{children:["This is a common pattern when using ",(0,s.jsx)(n.code,{children:"ParquetDataCatalog.from_env()"})," - make sure your ",(0,s.jsx)(n.code,{children:"NAUTILUS_PATH"})," points to the parent directory, not the catalog directory itself."]})]}),"\n",(0,s.jsx)(n.p,{children:"The following example shows how to initialize a data catalog where there is pre-existing data already written to disk at the given path."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from pathlib import Path\nfrom nautilus_trader.persistence.catalog import ParquetDataCatalog\n\n\nCATALOG_PATH = Path.cwd() / "catalog"\n\n# Create a new catalog instance\ncatalog = ParquetDataCatalog(CATALOG_PATH)\n\n# Alternative: Environment-based initialization\ncatalog = ParquetDataCatalog.from_env()  # Uses NAUTILUS_PATH environment variable\n'})}),"\n",(0,s.jsx)(n.h3,{id:"filesystem-protocols-and-storage-options",children:"Filesystem protocols and storage options"}),"\n",(0,s.jsx)(n.p,{children:"The catalog supports multiple filesystem protocols through fsspec integration, enabling seamless operation across local and cloud storage systems."}),"\n",(0,s.jsx)(n.h4,{id:"supported-filesystem-protocols",children:"Supported filesystem protocols"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsxs)(n.strong,{children:["Local filesystem (",(0,s.jsx)(n.code,{children:"file"}),"):"]})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'catalog = ParquetDataCatalog(\n    path="/path/to/catalog",\n    fs_protocol="file",  # Default protocol\n)\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsxs)(n.strong,{children:["Amazon S3 (",(0,s.jsx)(n.code,{children:"s3"}),"):"]})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'catalog = ParquetDataCatalog(\n    path="s3://my-bucket/nautilus-data/",\n    fs_protocol="s3",\n    fs_storage_options={\n        "key": "your-access-key-id",\n        "secret": "your-secret-access-key",\n        "region": "us-east-1",\n        "endpoint_url": "https://s3.amazonaws.com",  # Optional custom endpoint\n    }\n)\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsxs)(n.strong,{children:["Google Cloud Storage (",(0,s.jsx)(n.code,{children:"gcs"}),"):"]})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'catalog = ParquetDataCatalog(\n    path="gcs://my-bucket/nautilus-data/",\n    fs_protocol="gcs",\n    fs_storage_options={\n        "project": "my-project-id",\n        "token": "/path/to/service-account.json",  # Or "cloud" for default credentials\n    }\n)\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsxs)(n.strong,{children:["Azure Blob Storage (",(0,s.jsx)(n.code,{children:"abfs"}),"):"]})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'catalog = ParquetDataCatalog(\n    path="abfs://container@account.dfs.core.windows.net/nautilus-data/",\n    fs_protocol="abfs",\n    fs_storage_options={\n        "account_name": "your-storage-account",\n        "account_key": "your-account-key",\n        # Or use SAS token: "sas_token": "your-sas-token"\n    }\n)\n'})}),"\n",(0,s.jsx)(n.h4,{id:"uri-based-initialization",children:"URI-based initialization"}),"\n",(0,s.jsx)(n.p,{children:"For convenience, you can use URI strings that automatically parse protocol and storage options:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Local filesystem\ncatalog = ParquetDataCatalog.from_uri("/path/to/catalog")\n\n# S3 bucket\ncatalog = ParquetDataCatalog.from_uri("s3://my-bucket/nautilus-data/")\n\n# With storage options\ncatalog = ParquetDataCatalog.from_uri(\n    "s3://my-bucket/nautilus-data/",\n    storage_options={\n        "region": "us-east-1",\n        "access_key_id": "your-key",\n        "secret_access_key": "your-secret"\n    }\n)\n'})}),"\n",(0,s.jsx)(n.h3,{id:"writing-data",children:"Writing data"}),"\n",(0,s.jsxs)(n.p,{children:["Store data in the catalog using the ",(0,s.jsx)(n.code,{children:"write_data()"})," method. All Nautilus built-in ",(0,s.jsx)(n.code,{children:"Data"})," objects are supported, and any data which inherits from ",(0,s.jsx)(n.code,{children:"Data"})," can be written."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Write a list of data objects\ncatalog.write_data(quote_ticks)\n\n# Write with custom timestamp range\ncatalog.write_data(\n    trade_ticks,\n    start=1704067200000000000,  # Optional start timestamp override (UNIX nanoseconds)\n    end=1704153600000000000,    # Optional end timestamp override (UNIX nanoseconds)\n)\n\n# Skip disjoint check for overlapping data\ncatalog.write_data(bars, skip_disjoint_check=True)\n"})}),"\n",(0,s.jsx)(n.h3,{id:"file-naming-and-data-organization",children:"File naming and data organization"}),"\n",(0,s.jsxs)(n.p,{children:["The catalog automatically generates filenames based on the timestamp range of the data being written. Files are named using the pattern ",(0,s.jsx)(n.code,{children:"{start_timestamp}_{end_timestamp}.parquet"})," where timestamps are in ISO format."]}),"\n",(0,s.jsx)(n.p,{children:"Data is organized in directories by data type and instrument ID:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"catalog/\n\u251c\u2500\u2500 data/\n\u2502   \u251c\u2500\u2500 quote_ticks/\n\u2502   \u2502   \u2514\u2500\u2500 eurusd.sim/\n\u2502   \u2502       \u2514\u2500\u2500 20240101T000000000000000_20240101T235959999999999.parquet\n\u2502   \u2514\u2500\u2500 trade_ticks/\n\u2502       \u2514\u2500\u2500 btcusd.binance/\n\u2502           \u2514\u2500\u2500 20240101T000000000000000_20240101T235959999999999.parquet\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Rust backend data types (enhanced performance):"})}),"\n",(0,s.jsx)(n.p,{children:"The following data types use optimized Rust implementations:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"OrderBookDelta"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"OrderBookDeltas"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"OrderBookDepth10"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"QuoteTick"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"TradeTick"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"Bar"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"MarkPriceUpdate"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{type:"warning",children:(0,s.jsxs)(n.p,{children:["By default, data that overlaps with existing files will cause an assertion error to maintain data integrity. Use ",(0,s.jsx)(n.code,{children:"skip_disjoint_check=True"})," in ",(0,s.jsx)(n.code,{children:"write_data()"})," to bypass this check when needed."]})}),"\n",(0,s.jsx)(n.h3,{id:"reading-data",children:"Reading data"}),"\n",(0,s.jsxs)(n.p,{children:["Use the ",(0,s.jsx)(n.code,{children:"query()"})," method to read data back from the catalog:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from nautilus_trader.model import QuoteTick, TradeTick\n\n# Query quote ticks for a specific instrument and time range\nquotes = catalog.query(\n    data_cls=QuoteTick,\n    identifiers=["EUR/USD.SIM"],\n    start="2024-01-01T00:00:00Z",\n    end="2024-01-02T00:00:00Z"\n)\n\n# Query trade ticks with filtering\ntrades = catalog.query(\n    data_cls=TradeTick,\n    identifiers=["BTC/USD.BINANCE"],\n    start="2024-01-01",\n    end="2024-01-02",\n    where="price > 50000"\n)\n'})}),"\n",(0,s.jsxs)(n.h3,{id:"backtestdataconfig---data-specification-for-backtests",children:[(0,s.jsx)(n.code,{children:"BacktestDataConfig"})," - data specification for backtests"]}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"BacktestDataConfig"})," class is the primary mechanism for specifying data requirements before a backtest starts. It defines what data should be loaded from the catalog and how it should be filtered and processed during the backtest execution."]}),"\n",(0,s.jsx)(n.h4,{id:"core-parameters",children:"Core parameters"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Required parameters:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"catalog_path"}),": Path to the data catalog directory."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"data_cls"}),": The data type class (e.g., QuoteTick, TradeTick, OrderBookDelta, Bar)."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Optional parameters:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"catalog_fs_protocol"}),": Filesystem protocol ('file', 's3', 'gcs', etc.)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"catalog_fs_storage_options"}),": Storage-specific options (credentials, region, etc.)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"instrument_id"}),": Specific instrument to load data for."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"instrument_ids"}),": List of instruments (alternative to single instrument_id)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"start_time"}),": Start time for data filtering (ISO string or UNIX nanoseconds)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"end_time"}),": End time for data filtering (ISO string or UNIX nanoseconds)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"filter_expr"}),": Additional PyArrow filter expressions."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"client_id"}),": Client ID for custom data types."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"metadata"}),": Additional metadata for data queries."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"bar_spec"}),': Bar specification for bar data (e.g., "1-MINUTE-LAST").']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"bar_types"}),": List of bar types (alternative to bar_spec)."]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"basic-usage-examples",children:"Basic usage examples"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Loading quote ticks:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from nautilus_trader.config import BacktestDataConfig\nfrom nautilus_trader.model import QuoteTick, InstrumentId\n\ndata_config = BacktestDataConfig(\n    catalog_path="/path/to/catalog",\n    data_cls=QuoteTick,\n    instrument_id=InstrumentId.from_str("EUR/USD.SIM"),\n    start_time="2024-01-01T00:00:00Z",\n    end_time="2024-01-02T00:00:00Z",\n)\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Loading multiple instruments:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'data_config = BacktestDataConfig(\n    catalog_path="/path/to/catalog",\n    data_cls=TradeTick,\n    instrument_ids=["BTC/USD.BINANCE", "ETH/USD.BINANCE"],\n    start_time="2024-01-01T00:00:00Z",\n    end_time="2024-01-02T00:00:00Z",\n)\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Loading Bar Data:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'data_config = BacktestDataConfig(\n    catalog_path="/path/to/catalog",\n    data_cls=Bar,\n    instrument_id=InstrumentId.from_str("AAPL.NASDAQ"),\n    bar_spec="5-MINUTE-LAST",\n    start_time="2024-01-01",\n    end_time="2024-01-31",\n)\n'})}),"\n",(0,s.jsx)(n.h4,{id:"advanced-configuration-examples",children:"Advanced configuration examples"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Cloud Storage with Custom Filtering:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'data_config = BacktestDataConfig(\n    catalog_path="s3://my-bucket/nautilus-data/",\n    catalog_fs_protocol="s3",\n    catalog_fs_storage_options={\n        "key": "your-access-key",\n        "secret": "your-secret-key",\n        "region": "us-east-1"\n    },\n    data_cls=OrderBookDelta,\n    instrument_id=InstrumentId.from_str("BTC/USD.COINBASE"),\n    start_time="2024-01-01T09:30:00Z",\n    end_time="2024-01-01T16:00:00Z",\n    filter_expr="side == \'BUY\'",  # Only buy-side deltas\n)\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Custom Data with Client ID:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'data_config = BacktestDataConfig(\n    catalog_path="/path/to/catalog",\n    data_cls="my_package.data.NewsEventData",\n    client_id="NewsClient",\n    metadata={"source": "reuters", "category": "earnings"},\n    start_time="2024-01-01",\n    end_time="2024-01-31",\n)\n'})}),"\n",(0,s.jsx)(n.h4,{id:"integration-with-backtestrunconfig",children:"Integration with BacktestRunConfig"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"BacktestDataConfig"})," objects are integrated into the backtesting framework through ",(0,s.jsx)(n.code,{children:"BacktestRunConfig"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from nautilus_trader.config import BacktestRunConfig, BacktestVenueConfig\n\n# Define multiple data configurations\ndata_configs = [\n    BacktestDataConfig(\n        catalog_path="/path/to/catalog",\n        data_cls=QuoteTick,\n        instrument_id="EUR/USD.SIM",\n        start_time="2024-01-01",\n        end_time="2024-01-02",\n    ),\n    BacktestDataConfig(\n        catalog_path="/path/to/catalog",\n        data_cls=TradeTick,\n        instrument_id="EUR/USD.SIM",\n        start_time="2024-01-01",\n        end_time="2024-01-02",\n    ),\n]\n\n# Create backtest run configuration\nrun_config = BacktestRunConfig(\n    venues=[BacktestVenueConfig(name="SIM", oms_type="HEDGING")],\n    data=data_configs,  # List of data configurations\n    start="2024-01-01T00:00:00Z",\n    end="2024-01-02T00:00:00Z",\n)\n'})}),"\n",(0,s.jsx)(n.h4,{id:"data-loading-process",children:"Data loading process"}),"\n",(0,s.jsxs)(n.p,{children:["When a backtest runs, the ",(0,s.jsx)(n.code,{children:"BacktestNode"})," processes each ",(0,s.jsx)(n.code,{children:"BacktestDataConfig"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Catalog Loading"}),": Creates a ",(0,s.jsx)(n.code,{children:"ParquetDataCatalog"})," instance from the config."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Query Construction"}),": Builds query parameters from config attributes."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Data Retrieval"}),": Executes catalog queries using the appropriate backend."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Instrument Loading"}),": Loads instrument definitions if needed."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Engine Integration"}),": Adds data to the backtest engine with proper sorting."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"The system automatically handles:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Instrument ID resolution and validation."}),"\n",(0,s.jsx)(n.li,{children:"Data type validation and conversion."}),"\n",(0,s.jsx)(n.li,{children:"Memory-efficient streaming for large datasets."}),"\n",(0,s.jsx)(n.li,{children:"Error handling and logging."}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"datacatalogconfig---on-the-fly-data-loading",children:"DataCatalogConfig - on-the-fly data loading"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"DataCatalogConfig"})," class provides configuration for on-the-fly data loading scenarios, particularly useful for backtests where the number of possible instruments is vast,\nUnlike ",(0,s.jsx)(n.code,{children:"BacktestDataConfig"})," which pre-specifies data for backtests, ",(0,s.jsx)(n.code,{children:"DataCatalogConfig"})," enables flexible catalog access during runtime.\nCatalogs defined this way can also be used for requesting historical data."]}),"\n",(0,s.jsx)(n.h4,{id:"core-parameters-1",children:"Core parameters"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Required Parameters:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"path"}),": Path to the data catalog directory."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Optional Parameters:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"fs_protocol"}),": Filesystem protocol ('file', 's3', 'gcs', 'azure', etc.)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"fs_storage_options"}),": Protocol-specific storage options."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"name"}),": Optional name identifier for the catalog configuration."]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"basic-usage-examples-1",children:"Basic usage examples"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Local Catalog Configuration:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from nautilus_trader.persistence.config import DataCatalogConfig\n\ncatalog_config = DataCatalogConfig(\n    path="/path/to/catalog",\n    fs_protocol="file",\n    name="local_market_data"\n)\n\n# Convert to catalog instance\ncatalog = catalog_config.as_catalog()\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Cloud storage configuration:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'catalog_config = DataCatalogConfig(\n    path="s3://my-bucket/market-data/",\n    fs_protocol="s3",\n    fs_storage_options={\n        "key": "your-access-key",\n        "secret": "your-secret-key",\n        "region": "us-west-2",\n        "endpoint_url": "https://s3.us-west-2.amazonaws.com"\n    },\n    name="cloud_market_data"\n)\n'})}),"\n",(0,s.jsx)(n.h4,{id:"integration-with-live-trading",children:"Integration with live trading"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"DataCatalogConfig"})," is commonly used in live trading configurations for historical data access:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from nautilus_trader.config import TradingNodeConfig\nfrom nautilus_trader.persistence.config import DataCatalogConfig\n\n# Configure catalog for live system\ncatalog_config = DataCatalogConfig(\n    path="/data/nautilus/catalog",\n    fs_protocol="file",\n    name="historical_data"\n)\n\n# Use in trading node configuration\nnode_config = TradingNodeConfig(\n    # ... other configurations\n    catalog=catalog_config,  # Enable historical data access\n)\n'})}),"\n",(0,s.jsx)(n.h4,{id:"streaming-configuration",children:"Streaming configuration"}),"\n",(0,s.jsxs)(n.p,{children:["For streaming data to catalogs during live trading or backtesting, use ",(0,s.jsx)(n.code,{children:"StreamingConfig"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from nautilus_trader.persistence.config import StreamingConfig, RotationMode\nimport pandas as pd\n\nstreaming_config = StreamingConfig(\n    catalog_path="/path/to/streaming/catalog",\n    fs_protocol="file",\n    flush_interval_ms=1000,  # Flush every second\n    replace_existing=False,\n    rotation_mode=RotationMode.DAILY,\n    rotation_interval=pd.Timedelta(hours=1),\n    max_file_size=1024 * 1024 * 100,  # 100MB max file size\n)\n'})}),"\n",(0,s.jsx)(n.h4,{id:"use-cases",children:"Use cases"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Historical Data Analysis:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Load historical data during live trading for strategy calculations."}),"\n",(0,s.jsx)(n.li,{children:"Access reference data for instrument lookups."}),"\n",(0,s.jsx)(n.li,{children:"Retrieve past performance metrics."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Dynamic data loading:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Load data based on runtime conditions."}),"\n",(0,s.jsx)(n.li,{children:"Implement custom data loading strategies."}),"\n",(0,s.jsx)(n.li,{children:"Support multiple catalog sources."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Research and development:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Interactive data exploration in Jupyter notebooks."}),"\n",(0,s.jsx)(n.li,{children:"Ad-hoc analysis and backtesting."}),"\n",(0,s.jsx)(n.li,{children:"Data quality validation and monitoring."}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"query-system-and-dual-backend-architecture",children:"Query system and dual backend architecture"}),"\n",(0,s.jsx)(n.p,{children:"The catalog's query system leverages a sophisticated dual-backend architecture that automatically selects the optimal query engine based on data type and query parameters."}),"\n",(0,s.jsx)(n.h4,{id:"backend-selection-logic",children:"Backend selection logic"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Rust backend (high performance):"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Supported Types"}),": OrderBookDelta, OrderBookDeltas, OrderBookDepth10, QuoteTick, TradeTick, Bar, MarkPriceUpdate."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Conditions"}),": Used when ",(0,s.jsx)(n.code,{children:"files"})," parameter is None (automatic file discovery)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Benefits"}),": Optimized performance, memory efficiency, native Arrow integration."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"PyArrow backend (flexible):"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Supported Types"}),": All data types including custom data classes."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Conditions"}),": Used for custom data types or when ",(0,s.jsx)(n.code,{children:"files"})," parameter is specified."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Benefits"}),": Advanced filtering, custom data support, complex query expressions."]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"query-methods-and-parameters",children:"Query methods and parameters"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Core query parameters:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'catalog.query(\n    data_cls=QuoteTick,                    # Data type to query\n    identifiers=["EUR/USD.SIM"],           # Instrument identifiers\n    start="2024-01-01T00:00:00Z",         # Start time (various formats supported)\n    end="2024-01-02T00:00:00Z",           # End time\n    where="bid > 1.1000",                 # PyArrow filter expression\n    files=None,                           # Specific files (forces PyArrow backend)\n)\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Time format support:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["ISO 8601 strings: ",(0,s.jsx)(n.code,{children:'"2024-01-01T00:00:00Z"'}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["UNIX nanoseconds: ",(0,s.jsx)(n.code,{children:"1704067200000000000"})," (or ISO format: ",(0,s.jsx)(n.code,{children:'"2024-01-01T00:00:00Z"'}),")."]}),"\n",(0,s.jsxs)(n.li,{children:["Pandas Timestamps: ",(0,s.jsx)(n.code,{children:'pd.Timestamp("2024-01-01", tz="UTC")'}),"."]}),"\n",(0,s.jsx)(n.li,{children:"Python datetime objects (timezone-aware recommended)."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Advanced filtering examples:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Complex PyArrow expressions\ncatalog.query(\n    data_cls=TradeTick,\n    identifiers=["BTC/USD.BINANCE"],\n    where="price > 50000 AND size > 1.0",\n    start="2024-01-01",\n    end="2024-01-02",\n)\n\n# Multiple instruments with metadata filtering\ncatalog.query(\n    data_cls=Bar,\n    identifiers=["AAPL.NASDAQ", "MSFT.NASDAQ"],\n    where="volume > 1000000",\n    metadata={"bar_type": "1-MINUTE-LAST"},\n)\n'})}),"\n",(0,s.jsx)(n.h3,{id:"catalog-operations",children:"Catalog operations"}),"\n",(0,s.jsx)(n.p,{children:"The catalog provides several operation functions for maintaining and organizing data files. These operations help optimize storage, improve query performance, and ensure data integrity."}),"\n",(0,s.jsx)(n.h4,{id:"reset-file-names",children:"Reset file names"}),"\n",(0,s.jsx)(n.p,{children:"Reset parquet file names to match their actual content timestamps. This ensures filename-based filtering works correctly."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Reset all files in catalog:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Reset all parquet files in the catalog\ncatalog.reset_all_file_names()\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Reset specific data type:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Reset filenames for all quote tick files\ncatalog.reset_data_file_names(QuoteTick)\n\n# Reset filenames for specific instrument\'s trade files\ncatalog.reset_data_file_names(TradeTick, "BTC/USD.BINANCE")\n'})}),"\n",(0,s.jsx)(n.h4,{id:"consolidate-catalog",children:"Consolidate catalog"}),"\n",(0,s.jsx)(n.p,{children:"Combine multiple small parquet files into larger files to improve query performance and reduce storage overhead."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Consolidate entire catalog:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Consolidate all files in the catalog\ncatalog.consolidate_catalog()\n\n# Consolidate files within a specific time range\ncatalog.consolidate_catalog(\n    start="2024-01-01T00:00:00Z",\n    end="2024-01-02T00:00:00Z",\n    ensure_contiguous_files=True\n)\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Consolidate specific data type:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Consolidate all quote tick files\ncatalog.consolidate_data(QuoteTick)\n\n# Consolidate specific instrument\'s files\ncatalog.consolidate_data(\n    TradeTick,\n    identifier="BTC/USD.BINANCE",\n    start="2024-01-01",\n    end="2024-01-31"\n)\n'})}),"\n",(0,s.jsx)(n.h4,{id:"consolidate-catalog-by-period",children:"Consolidate catalog by period"}),"\n",(0,s.jsx)(n.p,{children:"Split data files into fixed time periods for standardized file organization."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Consolidate entire catalog by period:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import pandas as pd\n\n# Consolidate all files by 1-day periods\ncatalog.consolidate_catalog_by_period(\n    period=pd.Timedelta(days=1)\n)\n\n# Consolidate by 1-hour periods within time range\ncatalog.consolidate_catalog_by_period(\n    period=pd.Timedelta(hours=1),\n    start="2024-01-01T00:00:00Z",\n    end="2024-01-02T00:00:00Z"\n)\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Consolidate specific data by period:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Consolidate quote data by 4-hour periods\ncatalog.consolidate_data_by_period(\n    data_cls=QuoteTick,\n    period=pd.Timedelta(hours=4)\n)\n\n# Consolidate specific instrument by 30-minute periods\ncatalog.consolidate_data_by_period(\n    data_cls=TradeTick,\n    identifier="EUR/USD.SIM",\n    period=pd.Timedelta(minutes=30),\n    start="2024-01-01",\n    end="2024-01-31"\n)\n'})}),"\n",(0,s.jsx)(n.h4,{id:"delete-data-range",children:"Delete data range"}),"\n",(0,s.jsx)(n.p,{children:"Remove data within a specified time range for specific data types and instruments. This operation permanently deletes data and handles file intersections intelligently."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Delete entire catalog range:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Delete all data within a time range across the entire catalog\ncatalog.delete_catalog_range(\n    start="2024-01-01T00:00:00Z",\n    end="2024-01-02T00:00:00Z"\n)\n\n# Delete all data from the beginning up to a specific time\ncatalog.delete_catalog_range(end="2024-01-01T00:00:00Z")\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Delete specific data type:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Delete all quote tick data for a specific instrument\ncatalog.delete_data_range(\n    data_cls=QuoteTick,\n    identifier="BTC/USD.BINANCE"\n)\n\n# Delete trade data within a specific time range\ncatalog.delete_data_range(\n    data_cls=TradeTick,\n    identifier="EUR/USD.SIM",\n    start="2024-01-01T00:00:00Z",\n    end="2024-01-31T23:59:59Z"\n)\n'})}),"\n",(0,s.jsx)(n.admonition,{type:"warning",children:(0,s.jsx)(n.p,{children:"Delete operations permanently remove data and cannot be undone. Files that partially overlap the deletion range are split to preserve data outside the range."})}),"\n",(0,s.jsx)(n.h3,{id:"feather-streaming-and-conversion",children:"Feather streaming and conversion"}),"\n",(0,s.jsx)(n.p,{children:"The catalog supports streaming data to temporary feather files during backtests, which can then be converted to permanent parquet format for efficient querying."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Example: option greeks streaming"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from option_trader.greeks import GreeksData\nfrom nautilus_trader.persistence.config import StreamingConfig\n\n# 1. Configure streaming for custom data\nstreaming = StreamingConfig(\n    catalog_path=catalog.path,\n    include_types=[GreeksData],\n    flush_interval_ms=1000,\n)\n\n# 2. Run backtest with streaming enabled\nengine_config = BacktestEngineConfig(streaming=streaming)\nresults = node.run()\n\n# 3. Convert streamed data to permanent catalog\ncatalog.convert_stream_to_data(\n    results[0].instance_id,\n    GreeksData,\n)\n\n# 4. Query converted data\ngreeks_data = catalog.query(\n    data_cls=GreeksData,\n    start="2024-01-01",\n    end="2024-01-31",\n    where="delta > 0.5",\n)\n'})}),"\n",(0,s.jsx)(n.h3,{id:"catalog-summary",children:"Catalog summary"}),"\n",(0,s.jsx)(n.p,{children:"The NautilusTrader data catalog provides comprehensive market data management:"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Core features"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Dual Backend"}),": Rust performance + Python flexibility."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Multi-Protocol"}),": Local, S3, GCS, Azure storage."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Streaming"}),": Feather \u2192 Parquet conversion pipeline."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Operations"}),": Reset file names, consolidate data, period-based organization."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Key use cases"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Backtesting"}),": Pre-configured data loading via BacktestDataConfig."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Live Trading"}),": On-demand data access via DataCatalogConfig."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Maintenance"}),": File consolidation and organization operations."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Research"}),": Interactive querying and analysis."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"data-migrations",children:"Data migrations"}),"\n",(0,s.jsxs)(n.p,{children:["NautilusTrader defines an internal data format specified in the ",(0,s.jsx)(n.code,{children:"nautilus_model"})," crate.\nThese models are serialized into Arrow record batches and written to Parquet files.\nNautilus backtesting is most efficient when using these Nautilus-format Parquet files."]}),"\n",(0,s.jsxs)(n.p,{children:["However, migrating the data model between ",(0,s.jsx)(n.a,{href:"/getting_started/installation#precision-mode",children:"precision modes"})," and schema changes can be challenging.\nThis guide explains how to handle data migrations using our utility tools."]}),"\n",(0,s.jsx)(n.h3,{id:"migration-tools",children:"Migration tools"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"nautilus_persistence"})," crate provides two key utilities:"]}),"\n",(0,s.jsx)(n.h4,{id:"to_json",children:(0,s.jsx)(n.code,{children:"to_json"})}),"\n",(0,s.jsx)(n.p,{children:"Converts Parquet files to JSON while preserving metadata:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Creates two files:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"<input>.json"}),": Contains the deserialized data"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"<input>.metadata.json"}),": Contains schema metadata and row group configuration"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Automatically detects data type from filename:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"OrderBookDelta"}),' (contains "deltas" or "order_book_delta")']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"QuoteTick"}),' (contains "quotes" or "quote_tick")']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"TradeTick"}),' (contains "trades" or "trade_tick")']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"Bar"}),' (contains "bars")']}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"to_parquet",children:(0,s.jsx)(n.code,{children:"to_parquet"})}),"\n",(0,s.jsx)(n.p,{children:"Converts JSON back to Parquet format:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Reads both the data JSON and metadata JSON files."}),"\n",(0,s.jsx)(n.li,{children:"Preserves row group sizes from original metadata."}),"\n",(0,s.jsx)(n.li,{children:"Uses ZSTD compression."}),"\n",(0,s.jsxs)(n.li,{children:["Creates ",(0,s.jsx)(n.code,{children:"<input>.parquet"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"migration-process",children:"Migration process"}),"\n",(0,s.jsxs)(n.p,{children:["The following migration examples both use trades data (you can also migrate the other data types in the same way).\nAll commands should be run from the root of the ",(0,s.jsx)(n.code,{children:"persistence"})," crate directory."]}),"\n",(0,s.jsx)(n.h4,{id:"migrating-from-standard-precision-64-bit-to-high-precision-128-bit",children:"Migrating from standard-precision (64-bit) to high-precision (128-bit)"}),"\n",(0,s.jsx)(n.p,{children:"This example describes a scenario where you want to migrate from standard-precision schema to high-precision schema."}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsxs)(n.p,{children:["If you're migrating from a catalog that used the ",(0,s.jsx)(n.code,{children:"Int64"})," and ",(0,s.jsx)(n.code,{children:"UInt64"})," Arrow data types for prices and sizes,\nbe sure to check out commit ",(0,s.jsx)(n.a,{href:"https://github.com/nautechsystems/nautilus_trader/commit/e284162cf27a3222115aeb5d10d599c8cf09cf50",children:"e284162"}),"\n",(0,s.jsx)(n.strong,{children:"before"})," compiling the code that writes the initial JSON."]})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"1. Convert from standard-precision Parquet to JSON"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"cargo run --bin to_json trades.parquet\n"})}),"\n",(0,s.jsxs)(n.p,{children:["This will create ",(0,s.jsx)(n.code,{children:"trades.json"})," and ",(0,s.jsx)(n.code,{children:"trades.metadata.json"})," files."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"2. Convert from JSON to high-precision Parquet"}),":"]}),"\n",(0,s.jsxs)(n.p,{children:["Add the ",(0,s.jsx)(n.code,{children:"--features high-precision"})," flag to write data as high-precision (128-bit) schema Parquet."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"cargo run --features high-precision --bin to_parquet trades.json\n"})}),"\n",(0,s.jsxs)(n.p,{children:["This will create a ",(0,s.jsx)(n.code,{children:"trades.parquet"})," file with high-precision schema data."]}),"\n",(0,s.jsx)(n.h4,{id:"migrating-schema-changes",children:"Migrating schema changes"}),"\n",(0,s.jsx)(n.p,{children:"This example describes a scenario where you want to migrate from one schema version to another."}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"1. Convert from old schema Parquet to JSON"}),":"]}),"\n",(0,s.jsxs)(n.p,{children:["Add the ",(0,s.jsx)(n.code,{children:"--features high-precision"})," flag if the source data uses a high-precision (128-bit) schema."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"cargo run --bin to_json trades.parquet\n"})}),"\n",(0,s.jsxs)(n.p,{children:["This will create ",(0,s.jsx)(n.code,{children:"trades.json"})," and ",(0,s.jsx)(n.code,{children:"trades.metadata.json"})," files."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"2. Switch to new schema version"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"git checkout <new-version>\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"3. Convert from JSON back to new schema Parquet"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"cargo run --features high-precision --bin to_parquet trades.json\n"})}),"\n",(0,s.jsxs)(n.p,{children:["This will create a ",(0,s.jsx)(n.code,{children:"trades.parquet"})," file with the new schema."]}),"\n",(0,s.jsx)(n.h3,{id:"best-practices",children:"Best practices"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Always test migrations with a small dataset first."}),"\n",(0,s.jsx)(n.li,{children:"Maintain backups of original files."}),"\n",(0,s.jsx)(n.li,{children:"Verify data integrity after migration."}),"\n",(0,s.jsx)(n.li,{children:"Perform migrations in a staging environment before applying them to production data."}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"custom-data",children:"Custom data"}),"\n",(0,s.jsx)(n.p,{children:"Due to the modular nature of the Nautilus design, it is possible to set up systems\nwith very flexible data streams, including custom user-defined data types. This\nguide covers some possible use cases for this functionality."}),"\n",(0,s.jsxs)(n.p,{children:["It's possible to create custom data types within the Nautilus system. First you\nwill need to define your data by subclassing from ",(0,s.jsx)(n.code,{children:"Data"}),"."]}),"\n",(0,s.jsx)(n.admonition,{type:"info",children:(0,s.jsxs)(n.p,{children:["As ",(0,s.jsx)(n.code,{children:"Data"})," holds no state, it is not strictly necessary to call ",(0,s.jsx)(n.code,{children:"super().__init__()"}),"."]})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from nautilus_trader.core import Data\n\n\nclass MyDataPoint(Data):\n    """\n    This is an example of a user-defined data class, inheriting from the base class `Data`.\n\n    The fields `label`, `x`, `y`, and `z` in this class are examples of arbitrary user data.\n    """\n\n    def __init__(\n        self,\n        label: str,\n        x: int,\n        y: int,\n        z: int,\n        ts_event: int,\n        ts_init: int,\n    ) -> None:\n        self.label = label\n        self.x = x\n        self.y = y\n        self.z = z\n        self._ts_event = ts_event\n        self._ts_init = ts_init\n\n    @property\n    def ts_event(self) -> int:\n        """\n        UNIX timestamp (nanoseconds) when the data event occurred.\n\n        Returns\n        -------\n        int\n\n        """\n        return self._ts_event\n\n    @property\n    def ts_init(self) -> int:\n        """\n        UNIX timestamp (nanoseconds) when the object was initialized.\n\n        Returns\n        -------\n        int\n\n        """\n        return self._ts_init\n\n'})}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"Data"})," abstract base class acts as a contract within the system and requires two properties\nfor all types of data: ",(0,s.jsx)(n.code,{children:"ts_event"})," and ",(0,s.jsx)(n.code,{children:"ts_init"}),". These represent the UNIX nanosecond timestamps\nfor when the event occurred and when the object was initialized, respectively."]}),"\n",(0,s.jsxs)(n.p,{children:["The recommended approach to satisfy the contract is to assign ",(0,s.jsx)(n.code,{children:"ts_event"})," and ",(0,s.jsx)(n.code,{children:"ts_init"}),"\nto backing fields, and then implement the ",(0,s.jsx)(n.code,{children:"@property"})," for each as shown above\n(for completeness, the docstrings are copied from the ",(0,s.jsx)(n.code,{children:"Data"})," base class)."]}),"\n",(0,s.jsx)(n.admonition,{type:"info",children:(0,s.jsxs)(n.p,{children:["These timestamps enable Nautilus to correctly order data streams for backtests\nusing monotonically increasing ",(0,s.jsx)(n.code,{children:"ts_init"})," UNIX nanoseconds."]})}),"\n",(0,s.jsxs)(n.p,{children:["We can now work with this data type for backtesting and live trading. For instance,\nwe could now create an adapter which is able to parse and create objects of this\ntype - and send them back to the ",(0,s.jsx)(n.code,{children:"DataEngine"})," for consumption by subscribers."]}),"\n",(0,s.jsx)(n.p,{children:"You can publish a custom data type within your actor/strategy using the message bus\nin the following way:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'self.publish_data(\n    DataType(MyDataPoint, metadata={"some_optional_category": 1}),\n    MyDataPoint(...),\n)\n'})}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"metadata"})," dictionary optionally adds more granular information that is used in the\ntopic name to publish data with the message bus."]}),"\n",(0,s.jsxs)(n.p,{children:["Extra metadata information can also be passed to a ",(0,s.jsx)(n.code,{children:"BacktestDataConfig"})," configuration object in order to\nenrich and describe custom data objects used in a backtesting context:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from nautilus_trader.config import BacktestDataConfig\n\ndata_config = BacktestDataConfig(\n    catalog_path=str(catalog.path),\n    data_cls=MyDataPoint,\n    metadata={"some_optional_category": 1},\n)\n'})}),"\n",(0,s.jsx)(n.p,{children:"You can subscribe to custom data types within your actor/strategy in the following way:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'self.subscribe_data(\n    data_type=DataType(MyDataPoint,\n    metadata={"some_optional_category": 1}),\n    client_id=ClientId("MY_ADAPTER"),\n)\n'})}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"client_id"})," provides an identifier to route the data subscription to a specific client."]}),"\n",(0,s.jsxs)(n.p,{children:["This will result in your actor/strategy passing these received ",(0,s.jsx)(n.code,{children:"MyDataPoint"}),"\nobjects to your ",(0,s.jsx)(n.code,{children:"on_data"})," method. You will need to check the type, as this\nmethod acts as a flexible handler for all custom data."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def on_data(self, data: Data) -> None:\n    # First check the type of data\n    if isinstance(data, MyDataPoint):\n        # Do something with the data\n"})}),"\n",(0,s.jsx)(n.h3,{id:"publishing-and-receiving-signal-data",children:"Publishing and receiving signal data"}),"\n",(0,s.jsxs)(n.p,{children:["Here is an example of publishing and receiving signal data using the ",(0,s.jsx)(n.code,{children:"MessageBus"})," from an actor or strategy.\nA signal is an automatically generated custom data identified by a name containing only one value of a basic type\n(str, float, int, bool or bytes)."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'self.publish_signal("signal_name", value, ts_event)\nself.subscribe_signal("signal_name")\n\ndef on_signal(self, signal):\n    print("Signal", data)\n'})}),"\n",(0,s.jsx)(n.h3,{id:"option-greeks-example",children:"Option greeks example"}),"\n",(0,s.jsxs)(n.p,{children:["This example demonstrates how to create a custom data type for option Greeks, specifically the delta.\nBy following these steps, you can create custom data types, subscribe to them, publish them, and store\nthem in the ",(0,s.jsx)(n.code,{children:"Cache"})," or ",(0,s.jsx)(n.code,{children:"ParquetDataCatalog"})," for efficient retrieval."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import msgspec\nfrom nautilus_trader.core import Data\nfrom nautilus_trader.core.datetime import unix_nanos_to_iso8601\nfrom nautilus_trader.model import DataType\nfrom nautilus_trader.serialization.base import register_serializable_type\nfrom nautilus_trader.serialization.arrow.serializer import register_arrow\nimport pyarrow as pa\n\nfrom nautilus_trader.model import InstrumentId\nfrom nautilus_trader.core.datetime import dt_to_unix_nanos, unix_nanos_to_dt, format_iso8601\n\n\nclass GreeksData(Data):\n    def __init__(\n        self, instrument_id: InstrumentId = InstrumentId.from_str("ES.GLBX"),\n        ts_event: int = 0,\n        ts_init: int = 0,\n        delta: float = 0.0,\n    ) -> None:\n        self.instrument_id = instrument_id\n        self._ts_event = ts_event\n        self._ts_init = ts_init\n        self.delta = delta\n\n    def __repr__(self):\n        return (f"GreeksData(ts_init={unix_nanos_to_iso8601(self._ts_init)}, instrument_id={self.instrument_id}, delta={self.delta:.2f})")\n\n    @property\n    def ts_event(self):\n        return self._ts_event\n\n    @property\n    def ts_init(self):\n        return self._ts_init\n\n    def to_dict(self):\n        return {\n            "instrument_id": self.instrument_id.value,\n            "ts_event": self._ts_event,\n            "ts_init": self._ts_init,\n            "delta": self.delta,\n        }\n\n    @classmethod\n    def from_dict(cls, data: dict):\n        return GreeksData(InstrumentId.from_str(data["instrument_id"]), data["ts_event"], data["ts_init"], data["delta"])\n\n    def to_bytes(self):\n        return msgspec.msgpack.encode(self.to_dict())\n\n    @classmethod\n    def from_bytes(cls, data: bytes):\n        return cls.from_dict(msgspec.msgpack.decode(data))\n\n    def to_catalog(self):\n        return pa.RecordBatch.from_pylist([self.to_dict()], schema=GreeksData.schema())\n\n    @classmethod\n    def from_catalog(cls, table: pa.Table):\n        return [GreeksData.from_dict(d) for d in table.to_pylist()]\n\n    @classmethod\n    def schema(cls):\n        return pa.schema(\n            {\n                "instrument_id": pa.string(),\n                "ts_event": pa.int64(),\n                "ts_init": pa.int64(),\n                "delta": pa.float64(),\n            }\n        )\n'})}),"\n",(0,s.jsx)(n.h4,{id:"publishing-and-receiving-data",children:"Publishing and receiving data"}),"\n",(0,s.jsxs)(n.p,{children:["Here is an example of publishing and receiving data using the ",(0,s.jsx)(n.code,{children:"MessageBus"})," from an actor or strategy:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'register_serializable_type(GreeksData, GreeksData.to_dict, GreeksData.from_dict)\n\ndef publish_greeks(self, greeks_data: GreeksData):\n    self.publish_data(DataType(GreeksData), greeks_data)\n\ndef subscribe_to_greeks(self):\n    self.subscribe_data(DataType(GreeksData))\n\ndef on_data(self, data):\n    if isinstance(GreeksData):\n        print("Data", data)\n'})}),"\n",(0,s.jsx)(n.h4,{id:"writing-and-reading-data-using-the-cache",children:"Writing and reading data using the cache"}),"\n",(0,s.jsxs)(n.p,{children:["Here is an example of writing and reading data using the ",(0,s.jsx)(n.code,{children:"Cache"})," from an actor or strategy:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def greeks_key(instrument_id: InstrumentId):\n    return f"{instrument_id}_GREEKS"\n\ndef cache_greeks(self, greeks_data: GreeksData):\n    self.cache.add(greeks_key(greeks_data.instrument_id), greeks_data.to_bytes())\n\ndef greeks_from_cache(self, instrument_id: InstrumentId):\n    return GreeksData.from_bytes(self.cache.get(greeks_key(instrument_id)))\n'})}),"\n",(0,s.jsx)(n.h4,{id:"writing-and-reading-data-using-a-catalog",children:"Writing and reading data using a catalog"}),"\n",(0,s.jsxs)(n.p,{children:["For streaming custom data to feather files or writing it to parquet files in a catalog\n(",(0,s.jsx)(n.code,{children:"register_arrow"})," needs to be used):"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"register_arrow(GreeksData, GreeksData.schema(), GreeksData.to_catalog, GreeksData.from_catalog)\n\nfrom nautilus_trader.persistence.catalog import ParquetDataCatalog\ncatalog = ParquetDataCatalog('.')\n\ncatalog.write_data([GreeksData()])\n"})}),"\n",(0,s.jsx)(n.h3,{id:"creating-a-custom-data-class-automatically",children:"Creating a custom data class automatically"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"@customdataclass"})," decorator enables the creation of a custom data class with default\nimplementations for all the features described above."]}),"\n",(0,s.jsx)(n.p,{children:"Each method can also be overridden if needed. Here is an example of its usage:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from nautilus_trader.model.custom import customdataclass\n\n\n@customdataclass\nclass GreeksTestData(Data):\n    instrument_id: InstrumentId = InstrumentId.from_str("ES.GLBX")\n    delta: float = 0.0\n\n\nGreeksTestData(\n    instrument_id=InstrumentId.from_str("CL.GLBX"),\n    delta=1000.0,\n    ts_event=1,\n    ts_init=2,\n)\n'})}),"\n",(0,s.jsx)(n.h4,{id:"custom-data-type-stub",children:"Custom data type stub"}),"\n",(0,s.jsxs)(n.p,{children:["To enhance development convenience and improve code suggestions in your IDE, you can create a ",(0,s.jsx)(n.code,{children:".pyi"}),"\nstub file with the proper constructor signature for your custom data types as well as type hints for attributes.\nThis is particularly useful when the constructor is dynamically generated at runtime, as it allows the IDE to recognize\nand provide suggestions for the class's methods and attributes."]}),"\n",(0,s.jsxs)(n.p,{children:["For instance, if you have a custom data class defined in ",(0,s.jsx)(n.code,{children:"greeks.py"}),", you can create a corresponding ",(0,s.jsx)(n.code,{children:"greeks.pyi"})," file\nwith the following constructor signature:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from nautilus_trader.core import Data\nfrom nautilus_trader.model import InstrumentId\n\n\nclass GreeksData(Data):\n    instrument_id: InstrumentId\n    delta: float\n\n    def __init__(\n        self,\n        ts_event: int = 0,\n        ts_init: int = 0,\n        instrument_id: InstrumentId = InstrumentId.from_str("ES.GLBX"),\n        delta: float = 0.0,\n  ) -> GreeksData: ...\n'})})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},9087:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>l});var a=t(6363);const s={},i=a.createContext(s);function r(e){const n=a.useContext(i);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),a.createElement(i.Provider,{value:n},e.children)}}}]);